"""
Phase Configuration Module
===========================

Handles model and thinking level configuration for different execution phases.
Reads configuration from task_metadata.json and provides resolved model IDs.
"""

import json
import logging
import os
from pathlib import Path
from typing import Literal, TypedDict

logger = logging.getLogger(__name__)

# Model shorthand to full model ID mapping
# Values must match apps/frontend/src/shared/constants/models.ts MODEL_ID_MAP
MODEL_ID_MAP: dict[str, str] = {
    "opus": "claude-opus-4-6",
    "opus-1m": "claude-opus-4-6",
    "opus-4.5": "claude-opus-4-5-20251101",
    "sonnet": "claude-sonnet-4-5-20250929",
    "haiku": "claude-haiku-4-5-20251001",
}

# Model shorthand to required SDK beta headers
# Maps model shorthands that need special beta flags (e.g., 1M context window)
MODEL_BETAS_MAP: dict[str, list[str]] = {
    "opus-1m": ["context-1m-2025-08-07"],
}

# Thinking level to budget tokens mapping
# Values must match apps/frontend/src/shared/constants/models.ts THINKING_BUDGET_MAP
THINKING_BUDGET_MAP: dict[str, int] = {
    "low": 1024,
    "medium": 4096,  # Moderate analysis
    "high": 16384,  # Deep thinking for QA review
}

# Effort level mapping for adaptive thinking models (e.g., Opus 4.6)
# These models support CLAUDE_CODE_EFFORT_LEVEL env var for effort-based routing
EFFORT_LEVEL_MAP: dict[str, str] = {"low": "low", "medium": "medium", "high": "high"}

# Models that support adaptive thinking via effort level (env var)
# These models get both max_thinking_tokens AND effort_level
ADAPTIVE_THINKING_MODELS: set[str] = {"claude-opus-4-6"}

# Spec runner phase-specific thinking levels
# Heavy phases use high for deep analysis
# Light phases use medium after compaction
SPEC_PHASE_THINKING_LEVELS: dict[str, str] = {
    # Heavy phases - high (discovery, spec creation, self-critique)
    "discovery": "high",
    "spec_writing": "high",
    "self_critique": "high",
    # Light phases - medium (after first invocation with compaction)
    "requirements": "medium",
    "research": "medium",
    "context": "medium",
    "planning": "medium",
    "validation": "medium",
    "quick_spec": "medium",
    "historical_context": "medium",
    "complexity_assessment": "medium",
}

# Default phase configuration (fallback, matches 'Balanced' profile)
DEFAULT_PHASE_MODELS: dict[str, str] = {
    "spec": "sonnet",
    "planning": "sonnet",  # Changed from "opus" (fix #433)
    "coding": "sonnet",
    "qa": "sonnet",
}

DEFAULT_PHASE_THINKING: dict[str, str] = {
    "spec": "medium",
    "planning": "high",
    "coding": "medium",
    "qa": "high",
}


class PhaseModelConfig(TypedDict, total=False):
    spec: str
    planning: str
    coding: str
    qa: str


class PhaseThinkingConfig(TypedDict, total=False):
    spec: str
    planning: str
    coding: str
    qa: str


class TaskMetadataConfig(TypedDict, total=False):
    """Structure of model-related fields in task_metadata.json"""

    isAutoProfile: bool
    phaseModels: PhaseModelConfig
    phaseThinking: PhaseThinkingConfig
    model: str
    thinkingLevel: str
    fastMode: bool


Phase = Literal["spec", "planning", "coding", "qa"]


def resolve_model_id(model: str) -> str:
    """
    Resolve a model shorthand (haiku, sonnet, opus) to a full model ID.
    If the model is already a full ID, return it unchanged.

    Priority:
    1. Environment variable override (from API Profile)
    2. Hardcoded MODEL_ID_MAP
    3. Pass through unchanged (assume full model ID)

    Args:
        model: Model shorthand or full ID

    Returns:
        Full Claude model ID
    """
    # Check for environment variable override (from API Profile custom model mappings)
    if model in MODEL_ID_MAP:
        env_var_map = {
            "haiku": "ANTHROPIC_DEFAULT_HAIKU_MODEL",
            "sonnet": "ANTHROPIC_DEFAULT_SONNET_MODEL",
            "opus": "ANTHROPIC_DEFAULT_OPUS_MODEL",
            "opus-1m": "ANTHROPIC_DEFAULT_OPUS_MODEL",
            # opus-4.5 intentionally omitted — always resolves to its hardcoded
            # model ID (claude-opus-4-5-20251101) regardless of env var overrides.
        }
        env_var = env_var_map.get(model)
        if env_var:
            env_value = os.environ.get(env_var)
            if env_value:
                return env_value

        # Fall back to hardcoded mapping
        return MODEL_ID_MAP[model]

    # Already a full model ID or unknown shorthand
    return model


def get_model_betas(model_short: str) -> list[str]:
    """
    Get required SDK beta headers for a model shorthand.

    Some model configurations (e.g., opus-1m for 1M context window) require
    passing beta headers to the Claude Agent SDK.

    Args:
        model_short: Model shorthand (e.g., 'opus', 'opus-1m', 'sonnet')

    Returns:
        List of beta header strings, or empty list if none required
    """
    return MODEL_BETAS_MAP.get(model_short, [])


VALID_THINKING_LEVELS = {"low", "medium", "high"}

# Mapping from legacy/removed thinking levels to valid ones
LEGACY_THINKING_LEVEL_MAP: dict[str, str] = {
    "ultrathink": "high",
    "none": "low",
}


def sanitize_thinking_level(thinking_level: str) -> str:
    """
    Validate and sanitize a thinking level string.

    Maps legacy values (e.g., 'ultrathink') to valid equivalents and falls
    back to 'medium' for completely unknown values. Used by CLI argparse
    handlers to make the backend resilient to invalid values from the frontend.

    Args:
        thinking_level: Raw thinking level string from CLI or task_metadata.json

    Returns:
        A valid thinking level string (low, medium, high)
    """
    if thinking_level in VALID_THINKING_LEVELS:
        return thinking_level

    mapped = LEGACY_THINKING_LEVEL_MAP.get(thinking_level, "medium")
    logger.warning("Invalid thinking level '%s' mapped to '%s'", thinking_level, mapped)
    return mapped


def get_thinking_budget(thinking_level: str) -> int:
    """
    Get the thinking budget for a thinking level.

    Args:
        thinking_level: Thinking level (low, medium, high)

    Returns:
        Token budget for extended thinking
    """
    if thinking_level not in THINKING_BUDGET_MAP:
        valid_levels = ", ".join(THINKING_BUDGET_MAP.keys())
        logger.warning(
            "Invalid thinking_level '%s'. Valid values: %s. Defaulting to 'medium'.",
            thinking_level,
            valid_levels,
        )
        return THINKING_BUDGET_MAP["medium"]

    return THINKING_BUDGET_MAP[thinking_level]


def load_task_metadata(spec_dir: Path) -> TaskMetadataConfig | None:
    """
    Load task_metadata.json from the spec directory.

    Args:
        spec_dir: Path to the spec directory

    Returns:
        Parsed task metadata or None if not found
    """
    metadata_path = spec_dir / "task_metadata.json"
    if not metadata_path.exists():
        return None

    try:
        with open(metadata_path, encoding="utf-8") as f:
            return json.load(f)
    except (json.JSONDecodeError, OSError):
        return None


def get_phase_model(
    spec_dir: Path,
    phase: Phase,
    cli_model: str | None = None,
) -> str:
    """
    Get the resolved model ID for a specific execution phase.

    Priority:
    1. CLI argument (if provided)
    2. Phase-specific config from task_metadata.json (if auto profile)
    3. Single model from task_metadata.json (if not auto profile)
    4. Default phase configuration

    Args:
        spec_dir: Path to the spec directory
        phase: Execution phase (spec, planning, coding, qa)
        cli_model: Model from CLI argument (optional)

    Returns:
        Resolved full model ID
    """
    # CLI argument takes precedence
    if cli_model:
        return resolve_model_id(cli_model)

    # Load task metadata
    metadata = load_task_metadata(spec_dir)

    if metadata:
        # Check for auto profile with phase-specific config
        if metadata.get("isAutoProfile") and metadata.get("phaseModels"):
            phase_models = metadata["phaseModels"]
            model = phase_models.get(phase, DEFAULT_PHASE_MODELS[phase])
            return resolve_model_id(model)

        # Non-auto profile: use single model
        if metadata.get("model"):
            return resolve_model_id(metadata["model"])

    # Fall back to default phase configuration
    return resolve_model_id(DEFAULT_PHASE_MODELS[phase])


def get_phase_model_betas(
    spec_dir: Path,
    phase: Phase,
    cli_model: str | None = None,
) -> list[str]:
    """
    Get required SDK beta headers for the model selected for a specific phase.

    Uses the same priority logic as get_phase_model() to determine which model
    shorthand is selected, then looks up any required beta headers.

    Args:
        spec_dir: Path to the spec directory
        phase: Execution phase (spec, planning, coding, qa)
        cli_model: Model from CLI argument (optional)

    Returns:
        List of beta header strings, or empty list if none required
    """
    # Determine the model shorthand (before resolution to full ID)
    if cli_model:
        return get_model_betas(cli_model)

    metadata = load_task_metadata(spec_dir)

    if metadata:
        if metadata.get("isAutoProfile") and metadata.get("phaseModels"):
            phase_models = metadata["phaseModels"]
            model_short = phase_models.get(phase, DEFAULT_PHASE_MODELS[phase])
            return get_model_betas(model_short)

        if metadata.get("model"):
            return get_model_betas(metadata["model"])

    return get_model_betas(DEFAULT_PHASE_MODELS[phase])


def get_phase_thinking(
    spec_dir: Path,
    phase: Phase,
    cli_thinking: str | None = None,
) -> str:
    """
    Get the thinking level for a specific execution phase.

    Priority:
    1. CLI argument (if provided)
    2. Phase-specific config from task_metadata.json (if auto profile)
    3. Single thinking level from task_metadata.json (if not auto profile)
    4. Default phase configuration

    Args:
        spec_dir: Path to the spec directory
        phase: Execution phase (spec, planning, coding, qa)
        cli_thinking: Thinking level from CLI argument (optional)

    Returns:
        Thinking level string
    """
    # CLI argument takes precedence
    if cli_thinking:
        return cli_thinking

    # Load task metadata
    metadata = load_task_metadata(spec_dir)

    if metadata:
        # Check for auto profile with phase-specific config
        if metadata.get("isAutoProfile") and metadata.get("phaseThinking"):
            phase_thinking = metadata["phaseThinking"]
            return phase_thinking.get(phase, DEFAULT_PHASE_THINKING[phase])

        # Non-auto profile: use single thinking level
        if metadata.get("thinkingLevel"):
            return metadata["thinkingLevel"]

    # Fall back to default phase configuration
    return DEFAULT_PHASE_THINKING[phase]


def get_phase_thinking_budget(
    spec_dir: Path,
    phase: Phase,
    cli_thinking: str | None = None,
) -> int:
    """
    Get the thinking budget tokens for a specific execution phase.

    Args:
        spec_dir: Path to the spec directory
        phase: Execution phase (spec, planning, coding, qa)
        cli_thinking: Thinking level from CLI argument (optional)

    Returns:
        Token budget for extended thinking
    """
    thinking_level = get_phase_thinking(spec_dir, phase, cli_thinking)
    return get_thinking_budget(thinking_level)


def get_phase_config(
    spec_dir: Path,
    phase: Phase,
    cli_model: str | None = None,
    cli_thinking: str | None = None,
) -> tuple[str, str, int]:
    """
    Get the full configuration for a specific execution phase.

    Args:
        spec_dir: Path to the spec directory
        phase: Execution phase (spec, planning, coding, qa)
        cli_model: Model from CLI argument (optional)
        cli_thinking: Thinking level from CLI argument (optional)

    Returns:
        Tuple of (model_id, thinking_level, thinking_budget)
    """
    model_id = get_phase_model(spec_dir, phase, cli_model)
    thinking_level = get_phase_thinking(spec_dir, phase, cli_thinking)
    thinking_budget = get_thinking_budget(thinking_level)

    return model_id, thinking_level, thinking_budget


def is_adaptive_model(model_id: str) -> bool:
    """
    Check if a model supports adaptive thinking via effort level.

    Adaptive models support the CLAUDE_CODE_EFFORT_LEVEL environment variable
    for effort-based routing in addition to max_thinking_tokens.

    Args:
        model_id: Full model ID (e.g., 'claude-opus-4-6')

    Returns:
        True if the model supports adaptive thinking
    """
    return model_id in ADAPTIVE_THINKING_MODELS


def get_thinking_kwargs_for_model(model_id: str, thinking_level: str) -> dict:
    """
    Get thinking-related kwargs for create_client() based on model type.

    For adaptive models (Opus 4.6): returns both max_thinking_tokens and effort_level.
    For other models (Sonnet, Haiku): returns only max_thinking_tokens.

    Args:
        model_id: Full model ID (e.g., 'claude-opus-4-6')
        thinking_level: Thinking level string (low, medium, high)

    Returns:
        Dict with 'max_thinking_tokens' and optionally 'effort_level'
    """
    kwargs: dict = {"max_thinking_tokens": get_thinking_budget(thinking_level)}
    if is_adaptive_model(model_id):
        kwargs["effort_level"] = EFFORT_LEVEL_MAP.get(thinking_level, "medium")
    return kwargs


def get_phase_client_thinking_kwargs(
    spec_dir: Path,
    phase: Phase,
    phase_model: str,
    cli_thinking: str | None = None,
) -> dict:
    """
    Get thinking kwargs for create_client() for a specific execution phase.

    Combines get_phase_thinking() and get_thinking_kwargs_for_model() to produce
    the correct kwargs dict based on phase config and model capabilities.

    Args:
        spec_dir: Path to the spec directory
        phase: Execution phase (spec, planning, coding, qa)
        phase_model: Resolved full model ID for this phase
        cli_thinking: Thinking level from CLI argument (optional)

    Returns:
        Dict with 'max_thinking_tokens' and optionally 'effort_level'
    """
    thinking_level = get_phase_thinking(spec_dir, phase, cli_thinking)
    return get_thinking_kwargs_for_model(phase_model, thinking_level)


def get_fast_mode(spec_dir: Path) -> bool:
    """
    Check if Fast Mode is enabled for this task.

    Fast Mode provides faster Opus 4.6 output at higher cost.
    Reads the fastMode flag from task_metadata.json.

    Args:
        spec_dir: Path to the spec directory

    Returns:
        True if Fast Mode is enabled, False otherwise
    """
    metadata = load_task_metadata(spec_dir)
    if metadata:
        enabled = bool(metadata.get("fastMode", False))
        if enabled:
            logger.info(
                "[Fast Mode] ENABLED — read fastMode=true from task_metadata.json"
            )
        else:
            logger.info("[Fast Mode] disabled — fastMode not set in task_metadata.json")
        return enabled
    logger.info("[Fast Mode] disabled — no task_metadata.json found")
    return False


def get_spec_phase_thinking_budget(phase_name: str) -> int:
    """
    Get the thinking budget for a specific spec runner phase.

    This maps granular spec phases (discovery, spec_writing, etc.) to their
    appropriate thinking budgets based on SPEC_PHASE_THINKING_LEVELS.

    Args:
        phase_name: Name of the spec phase (e.g., 'discovery', 'spec_writing')

    Returns:
        Token budget for extended thinking
    """
    thinking_level = SPEC_PHASE_THINKING_LEVELS.get(phase_name, "medium")
    return get_thinking_budget(thinking_level)
